{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE 120 Lab 2: Applications of LTI Filtering\n",
    "\n",
    "v1 - Spring 2019: Dominic Carrano, Sukrit Arora, and Babak Ayazifar  \n",
    "v2 - Fall 2019: Dominic Carrano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Now that you're familiar with the iPython notebook environment and the Python language's scientific computing capabilities, you'll get to put your skills to use in exploring some applications of LTI filtering!\n",
    "\n",
    "You'll see some examples of filters in this lab that you've probably also seen in class, such as the moving average or the edge detector. The difference here is that since we have a computer to do all the heavy lifting of computing convolutions and plotting things for us, we can explore how these filters behave when given much larger (and more interesting) signals. Specifically, we'll explore these two filters and several different interpretations of how they act on various types of signals, as well as their applications. After that, we'll delve into the MACD indicator, exploring how it's used in analysis of financial data on the stock market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous (Interpolated with `plt.plot`) vs Discrete (Stem with `plt.stem`) Plots\n",
    "\n",
    "While we're still considering our signals as discrete-time entities in this lab, many of them will be fairly long, containing hundreds or even thousands of signal values. As a result, you should **use `plt.plot` for plotting all signals in this lab, unless told otherwise**. \n",
    "\n",
    "We used `plt.stem` almost exclusively in Lab 1, but stem plots have two major disadvantages which continuous-time plots (i.e. ones generated with `plt.plot`, which interpolates your signals) don't suffer from:\n",
    "- It's difficult to overlay multiple signals on the same stem plot and visually compare them.\n",
    "- Stem plots' rendering times scale *significantly* worse with the length of the signal being plotted.\n",
    "    - Just to get a sense for how bad a stem plot is at scale, we compared times for plotting with `plt.stem` against `plt.plot` on a 2015 MacBook Pro. On average, for a length 1000 rect, `plt.plot` took ~100 ms and `plt.stem` took 2-3 seconds; for a length 10000 rect, `plt.plot` took ~200 ms and `plt.stem` took 1.5-2 ***minutes***.\n",
    "    - Remember the demo in Q3c of Lab 1 where we repeatedly convolved rects and saw that we eventually get a Gaussian (the bell curve)? You probably noticed that it took longer and longer to display the successive results - the issue wasn't that the convolutions were taking long due to the signal length increasing (the convolution runtime was increasing with the signal length, but negligibly so); rather the repeated stem plotting was the bottleneck.\n",
    "    \n",
    "The two reasons listed above are some reasons why almost all plots you'll see in real world applications are interpolated. Keep in mind that there's actually a more complicated interplay going on between the continuous and discrete realms when doing digital processing of signals:\n",
    "1. A continuous time signal $x(t)$ is sampled at some rate $T$, giving $N$ samples at integer multiples of $T$ as $x(nT)$. We then define $x[n] = x(nT)$, a discrete time signal, which we can work with on the computer; note that $n = 0,1,..., N-1$ since we only have $N$ samples. Most practical signals are finite in duration, however, and so $N$ can be chosen to be sufficiently high to capture the entire signal.\n",
    "2. Processing is done on $x[n]$ on a computer, to produce some related signal $y[n]$.\n",
    "3. $y[n]$ is plotted as a continuous-time signal via interpolation.\n",
    "\n",
    "Much like the conventions discussed in Lab 1 of what \"zero\" means as a time index, this is one of the nuances of how signals and systems is done in practice that you get used to with experience.\n",
    "\n",
    "In this lab, some of the signals we'll use are just made up \"test signals\" so we can experiment with different filters, in which case the above steps 1-3 aren't relevant. However, in other parts, we'll be using some real world data, and it's good to keep 1-3 straight in your head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: The 1D Edge Detector\n",
    "\n",
    "The 1D edge detector is used in signal processing to, as you may have guessed from the name, detect edges, or jumps in a signal's amplitude. It's referred to as 1D to distinguish it from 2D edge-detecting filters used in image processing â€” basic signals only containing amplitude versus time information are referred to as \"1D\" whereas images are often considered as \"2D\" signals. Videos are considered \"3D\" signals, with time (as you go from frame to frame) being the third dimension. Almost all signals you'll see in EE 120 will be 1D.\n",
    "\n",
    "The impulse response of a 1D edge detector is defined as:\n",
    "\n",
    "$$h[n] = \\delta[n] - \\delta[n - 1]$$\n",
    "\n",
    "In this question, we'll explore several important properties of the edge detector.\n",
    "\n",
    "The filter works by taking the difference between every pair of adjacent signal values. If you have a sequence of constant values, the filter will repeatedly output zeros, as there's no \"edge\". \n",
    "\n",
    "Similarly, if the signal has a zero (at time $n-1$) followed by a 1 (at time $n$), the filter will output a 1 (at time $n$), indicating an edge of \"size\" 1. The filter also encodes information about the edge's \"direction\" - if you instead had a 1 (at time $n-1$) followed by a 0 (at time $n$), the output (at time $n$) would be -1.\n",
    "\n",
    "Because of this, the 1D edge detector can be thought of as the discrete-time equivalent of taking a derivative, an idea we'll explore in greater depth in part b of this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1a: Piecewise Constant Signals\n",
    "\n",
    "We'll go through two examples with this filter. First, we'll try it out on a piecewise constant signal. We call a DT signal \"piecewise constant\" if it consists only of constant-height segments each spread over more than one sample. The first two signals below are piecewise constant; the third is not.\n",
    "\n",
    "<img src=\"q1pic.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Job\n",
    "\n",
    "In the cell below:  \n",
    "- Using the time indices $\\{0, 1, ..., 19, 20\\}$, define the piecewise constant signal $x$ as  \n",
    "\n",
    "$$x[n] = \\sum_{k = 5}^{9} \\delta[n - k] + 3\\sum_{k = 10}^{13} \\delta[n - k] + 2\\sum_{k = 14}^{18} \\delta[n - k]$$  \n",
    "\n",
    "\n",
    "- Define the edge detector's impulse response $h$, but only at its nonzero points (so that the numpy array representing $h$ contains two elements).\n",
    "    - Throughout this lab, we'll typically be defining our impulse responses over their nonzero points to avoid offset issues and using \"same\" for convolution. As you saw in Lab 1, \"same\" truncates convolved signals to the same length as the longer of the two arguments, cutting out points from the result's edges. Essentially, \"same\" acts just like \"full\" but with some truncation; we'll be zero padding the input signals as necessary to handle this.\n",
    "- Compute $y = x * h$ using \"same\" for the convolution mode.\n",
    "- Once done with the previous three steps, run the cell to plot the results (plotting code has been provided for you).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "n = \n",
    "h = \n",
    "x = \n",
    "y =  # filtered version of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.stem(n, x)\n",
    "plt.ylim([0, 3.5])\n",
    "plt.title(\"Piecewise Constant Signal $x[n]$\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.stem(n, y)\n",
    "plt.ylim([-2.5, 2.5])\n",
    "plt.title(\"1D Edge Detector Output for $x[n]$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** $x$ is a piecewise-constant signal, changing a total of four times: once from 0->1, then 1->3, then 3->2, and finally 2->0. How many points of the edge detector's output are nonzero (that is, how many edges are detected)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** One of the hottest areas of signal processing in the past ~15 years has been the study of sparse (mostly zero) signals, including both acquisition and representation, known as *compressed sensing*. A key part of compressed sensing algorithms is applying some *sparsifying transform* to signals that retain all the signal's information (i.e., the original signal could be completely recovered from the transformed one) but result in a new signal that is mostly zero. \n",
    "\n",
    "Suppose you're interested in developing compressed sensing algorithms for piecewise constant signals, and are in need of a way to sparsify them. How would you do so by only using the first signal value, $x(0)$, and using an LTI filter of your choice as the sparsifying transform? Explain both what LTI filter you would use, and how to recover the original signal from the filtered one. You can ignore noise that would be present for real world signals â€” assume the signal truly is piecewise-constant like the ones above. Also, you may assume $x(n) = 0$ for $n < 0$, since this is basically what we're doing in the digital setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1b: The Edge Detector as a DT Differentiator\n",
    "\n",
    "The 1D edge detector is sometimes also referred to as a *moving difference* filter, since it operates by subtracting adjacent points. This has a particularly nice connection to the idea from calculus of taking a derivative of a function, and many properties of the 1D edge detector can be discovered by considering it as a discrete-time analogue of taking a signal's derivative. \n",
    "\n",
    "Recall that given a function $f: \\mathbb{R} \\xrightarrow{} \\mathbb{R}$, the derivative of $f$ is defined as\n",
    "\n",
    "$$f'(t) = \\lim_{\\Delta t \\xrightarrow{} 0}\\dfrac{f(t + \\Delta t) - f(t)}{\\Delta t}$$\n",
    "\n",
    "and as we make $\\Delta t$ smaller and smaller, we get better and better approximations of $f'(t)$. But in DT, all arguments to our signals have to be integers, so $\\Delta t$ has to be an integer. The smallest it could then be, without actually being zero, is 1, in which case we recover the formula for the 1D edge detector!\n",
    "\n",
    "Let's revisit some of the classic results you saw in your first calculus class, but instead of using functions that take real numbers as inputs, we'll use DT signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Job\n",
    "\n",
    "In the cell below:\n",
    "- Create a length 50 *ramp signal* $r$, defined as\n",
    "$$r[n] = \\sum_{k=1}^{50} k \\delta[n - k] = \\delta[n - 1] + 2 \\delta[n - 2] + 3 \\delta[n - 3] + ... + 50 \\delta[n - 50]$$\n",
    "- Compute $y = r * h$, where $h$ is the (non zero-padded) 1D edge detector's impulse response, just as in Q1a. **Use \"valid\" as the convolution mode** - we only want to difference values from our actual signal (i.e. where $x$ and $h$ fully overlap).\n",
    "- In separate figures (or you can use two subplots inside the same figure as was done in the provided code for Q1a; up to you), one above the other, plot $r$ and $y$ (plot $r$ on the top figure and $y$ on the bottom one). A few instructions regarding your plot:\n",
    "    - **Use `plt.stem` to make stem plots**.\n",
    "    - Give your plots reasonable titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** A ramp signal linearly increases. You should see in your plot that a 1D edge detector, or moving difference, outputs a constant signal when given a ramp as its input. What real function ($f(t) = ?$) does the ramp remind you of? What is that function's derivative (what's $f'(t)$)? How does the derivative for it match up against the edge detector's output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another! In the cell below:\n",
    "- Create a length 51 quadratic signal $x[n] = n^2$ for $n = 0, 1, ..., 50$.\n",
    "- Compute $y = r * h$ just as you did in the previous example, where $h$ is the (unpadded) 1D edge detector's impulse response. Again, use \"valid\" for the mode.\n",
    "- Plot $x$ and $y$ the same way you plotted $r$ and $y$ in the previous example, in separate plots with $x$'s above $y$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Same question as before. You should see in your plot that a 1D edge detector, or moving difference, outputs a ramp signal when given a quadratic as its input. What real function ($f(t) = ?$) does the quadratic remind you of? What is that function's derivative (what's $f'(t)$)? How does the derivative for it match up against the edge detector's output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1c: \"Differentiating\" Noise\n",
    "\n",
    "Now that we've tried our edge detector on a piecewise constant signal, let's try it on a less well-behaved signal: some noise! In this part, as well as the moving average filter, we'll use what's commonly referred to as \"Gaussian noise\" as our test signal. \n",
    "\n",
    "### What is this \"noise\" you speak of?\n",
    "\n",
    "In many real-world applications, when using some data that has been collected (i.e., a signal), you don't have access to the original signal (call it $x$). Instead, you have access to $\\tilde{x} = x + z$, where $z$ is \"noise\" that corrupts the signal. A large part of signal processing, machine learning, statistics, data science, and many other application areas involves extracting as much meaning as possible from the measured signal $\\tilde{x}$. A popular choice for modeling $z$ is what's known as \"Gaussian noise\". The name comes from the fact that the noise itself is random, and so it has to be drawn from some probability distribution, which in this case is the Gaussian distribution. The justification for this choice is due to the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem), since in many cases, the noise riding on top of a signal is a superposition of a large number of various random factors. For example, the [thermal noise](https://en.wikipedia.org/wiki/Johnson%E2%80%93Nyquist_noise) in electronics from interactions between particles as they bounce around and hit each other has been found to be very close to Gaussian, which makes sense, as the number of individual atoms involved is large, with each pair of interacting atoms serving as a separate random event.\n",
    "\n",
    "As was mentioned in Lab 1, you don't need to know probability theory for this class. But due to the popularity of the Gaussian noise model in signal processing, it's worth experimenting with as a test signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Job\n",
    "\n",
    "The signal `noise` is defined for you below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 5, 1000) # 1000 samples of mean=0, stddev=5 gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add code to apply the (unpadded, i.e. the numpy array is length 2) edge detector to it, and store the result in `noise_filt`. Again, use \"valid\" as the convolution mode. Plotting code has been provided for you. You don't have to do much coding for this part.\n",
    "\n",
    "Note that we'll start using `plt.plot` from here on out. We'll be using longer signals (we generated 1000 samples of noise) and in addition to `plt.plot` being more efficient, it'll be much easier to visualize our results, as mentioned in \"Background\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO your filtering code here; store result in noise_filt\n",
    "noise_filt =  # filtered result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The signals `noise_filt` and `noise` will not necessarily fit within the -20 to 20 y-limits we've set for the plot. Since it's random, it's possible we'll draw values that, either before or after filtering, will go outside these limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(noise)\n",
    "plt.plot(noise_filt)\n",
    "plt.ylim([-20, 20])\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend((\"Gaussian Noise\", \"1D Edge Detector Output for Gaussian Noise\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Qualitatively, does the filter amplify or suppress the \"strength\" of the noise? What implications might this have if we want to detect edges on a signal that has been corrupted by a large amount of noise?\n",
    "\n",
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Data Smoothing\n",
    "\n",
    "One of the most common uses of LTI filters is in data smoothing. The applications are numerous, ranging from noise reduction, to extracting trends from complex data, to interpolation, and more. In this question, we'll explore the simplest, yet perhaps most widely used, data smoothing method in a few of these application spaces: a moving average filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2a: Noise Reduction\n",
    "\n",
    "The *simple* moving average filter is specified in terms of a single integer parameter, $L$, which represents the length of the filter. The filter takes the average of the $L$ points before, and including, the current point of a signal, outputting that average. Formally, the filter's impulse response is:\n",
    "\n",
    "$$h_{SMA}[n] = \\frac{\\delta[n] + \\delta[n - 1]\\ +\\ ...\\ +\\ \\delta[n - (L - 1)]}{L}$$\n",
    "\n",
    "Note that the definition we'll use here is for the *causal* moving average filter: the output at any point in time is only computed as an average of the current and previous signal values. You probably recognize the impulse response - it's just a length $L$ rect normalized to sum to 1. \n",
    "\n",
    "The subscript \"SMA\" in the impulse response definition stands for *Simple Moving Average*, meaning all points are given equal weight in computing the average. This distinguishes the filter from more elaborate moving averages, such as the *Exponential Moving Average* (EMA) which gives more recent data points a higher weight. You'll get a chance to explore the EMA later in this Lab. We encourage you to check out reference [1] for more on the theory behind the use of moving average filters for noise reduction if interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Job: Signal Generation\n",
    "\n",
    "In the cell below, do the following:\n",
    "- Generate the time indices $\\{0, 1, ..., 999, 1000\\}$.\n",
    "- Generate the signal $x[n] = e^{n / 300}$ over these time indices.\n",
    "- Append 500 zeros onto the end of $x$, and extend your time indices to account for these extra data points. That is, your time indices should now be $\\{0, 1, ..., 1000, 1001, ..., 1500\\}$.\n",
    "- Generate noise $z$ of the same dimensions as $x$, by using [np.random.normal](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html) with the parameters `loc=0, scale=4, size=np.shape(x)`. \n",
    "    - As a reminder from Lab 1 Q1, `np.shape(x)` returns how many entries `x` has along each dimension (here, our signal is 1D, so `np.shape` just returns the number of entries), which we can pass into a numpy function to easily generate numpy arrays (i.e. signals) of the same size as some other numpy array. \n",
    "- Create the noised signal $y = x + z$.\n",
    "- On the same 16x4 figure, plot $x$ and $y$. Using [plt.legend](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.legend.html), label $x$ as \"True Signal\" and $y$ as \"Noised Signal\". **Make sure you use `plt.plot`, *not* `plt.stem`, for plotting.** You should use the time indices you generated as the first argument to `plt.plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, you should see an exponential that rises in amplitude from 0 to ~30 over the course of the first 1000 samples followed by 500 zeros. Overlayed on top of it, you'll see a signal that jumps up and down, **but, on average, follows the sample amplitude as the original signal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Job: Signal Denoising\n",
    "\n",
    "Now that we've got a (not so) nice and noised up signal, let's try to denoise it with a moving average. Intuitively, since the noised signal follows, on average, the original one, we should be able to reduce the noise a bit by averaging adjacent data points. The hard part, and a great example of an engineering tradeoff, is figuring out the right number of points to average at a time. \n",
    "\n",
    "The array `filt_sizes` containing the different sizes (the parameter $L$ from above) we'll try out has been defined for you. In the cell below:\n",
    "- Create a 20x35 figure. We will be creating a column of subplots, one for each filter length (note `len(filt_sizes)` is 7).\n",
    "- For each filter size in `filt_sizes`,\n",
    "    - Create a simple moving average filter, $h$, of that size.\n",
    "        - Don't bother doing any zero padding of $h$. Instead, just construct the filter for all points where it is nonzero.\n",
    "    - Compute $\\hat{x} = y * h$, where $y$ is the noised growing exponential signal you created above. Naming this variable `x_hat` in your code is fine. **Use \"full\" as the convolution mode.** If we don't use \"full\", the filter will be non-causal due to the way we defined the impulse response. \n",
    "    - On a new subplot (that is, for each different moving average filter, we're using a separate subplot):\n",
    "        - Plot $x$, the original (noiseless) signal. You can use the variable $n$ from above for the time indices.\n",
    "        - Plot $\\hat{x}$, the moving averaged version of $y$ you computed in the current loop iteration. \n",
    "            - Since we didn't use \"same\" for the convolution (motivated by the desire to have a causal filter), we need an expanded set of time indices to plot with. \n",
    "            - As a freebie, the code for this is `n_aug = np.concatenate((n, np.arange(n[-1], n[-1] + (len(x_hat) - len(n)))))`. This just adds on the extra indices to the end of the existing ones based on how much the convolution stretches the signal $x$ by.\n",
    "        - Use `plt.legend` to label $x$ as \"True Signal\" and $\\hat{x}$ as \"Noised Signal after ?-point SMA\", where \"?\" should be replaced by the current filter size. Python's [format](https://www.digitalocean.com/community/tutorials/how-to-use-string-formatters-in-python-3) function may be of use here.\n",
    "\n",
    "**Note:** $\\hat{x}$ and $h$ change with each new filter size; $x$ and $y$ do not.\n",
    "\n",
    "**Hint 1:** It will be most informative to display our subplots as a column. Thus, your call to `plt.subplot` should look something like `plt.subplot(len(filt_sizes), 1, i)`  where `i` is a variable tracking which subplot we're currently on (i.e., it starts at 1, and should increase by 1 each time we create and apply a different moving average filter).\n",
    "\n",
    "**Hint 2:** Make sure to call `plt.show()` *after* you've created all your subplots (i.e., it should NOT be called inside a loop). You only call `plt.show()` once per figure, i.e. after you're finished generating all the subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filt_sizes = [2, 5, 10, 20, 50, 100, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few sanity checks:\n",
    "- In all cases, the true signal should go from 0 to 1500 and look the same.\n",
    "- As we increase the filter length, the noised signal (post-filtering) will be stretched further and further out, occupying just over 1500 points for the length 2 and length 5 filters, and about 2000 points for the length 500 filter.\n",
    "- The peak of the noised signal (post-filtering) should always line up with the true signal's peak. This is a good sanity check that the filter is causal: if it doesn't look ahead, then the filter's first encounter with the peak will be averaging the peak with the previous (positive) values, resulting in a peak in the output. After the filter sees the true signal's peak, it only sees zeros, so averaging in more and more zeros instead of the positive values on the exponential will lead to smaller and smaller output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** As we increase the filter length, do the first 400-500 points of the filtered signal get smoothed out (reducing the noise at these points) or blown up (amplifying the noise)? Ignore any scaling differences; that is, if the filtered signal looks the same as the true one except for being off by a constant scaling factor, that's fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** As we increase the filter length, what happens to our signal's sharp, high-frequency feature, the drop off from the top of the exponential back down to zero (at $n=1000$)? Is this high-frequency feature preserved, or does it get more and more distorted? Explain, based on the moving average filter, why this makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO).</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Putting your previous answers together, what advantage is there to using a longer moving average for noise reduction? What do we have to trade off (i.e., what disadvantage becomes more and more pronounced) in doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Assuming you equally prioritize minimizing distortion of sharp, high-frequency features while still getting a reasonable amount of noise reduction, which of the following moving average filter lengths would you pick from above for denoising this specific signal? There are multiple correct answers; just be sure to justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2b: Extracting Trends from Data\n",
    "\n",
    "In addition to its use in signal processing and statistics for noise reduction, the moving average filter is popular in analysis of financial data for highlighting trends in stock prices.\n",
    "\n",
    "Here, we'll analyze one of the most common datasets in time series analysis: stock price data! Run the cell below to load it. We will be taking a look at Apple's stock data from mid 2017 to early 2019.\n",
    "\n",
    "We got this data from Yahoo! finance. If you are interested in playing around with stock data on your own, you can click on a stock, navigate to the historical data tab, download a csv file, and use our code below to parse it. Acquiring data often plays second fiddle to all the fancy algorithms used on it despite being just as important a part of any engineering field that relies on it. However, here, we want to focus on the algorithms, not the minutiae of Yahoo! csv file formats, hence why we provide the code to read the data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV hocus pocus\n",
    "import csv\n",
    "\n",
    "stock_dates = []\n",
    "stock_prices  = []\n",
    "with open('AAPL.csv', mode='r') as raw_data:\n",
    "    csv_reader = csv.DictReader(raw_data)\n",
    "    for row in csv_reader:\n",
    "        data = row['Close']\n",
    "        if not data == 'null':\n",
    "            stock_prices.append(float(data))\n",
    "            stock_dates.append(row['Date'])\n",
    "stock_prices = np.array(stock_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400 most recent days\n",
    "start = -400\n",
    "end = -1\n",
    "x = np.arange(len(stock_prices[start:end]))\n",
    "\n",
    "# Plot roughly one data point per week (x[::7]) so we can display dates \n",
    "# without matplotlib going crazy about the labels overlapping\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.xticks(x[::7], stock_dates[start:end:7], fontsize=10, rotation=75)\n",
    "plt.plot(x, stock_prices[start:end])\n",
    "plt.title(\"AAPL Daily Closing Prices, June 2017 to January 2019\")\n",
    "plt.ylabel(\"US Dollars\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task\n",
    "\n",
    "Your job is to fill in the missing parts of the cell below to filter the noise with moving average filters of length 5, 25, and 75, and be sure to answer the question about interpreting the results below the cell. Unlike Q2a, most of the work has been done for you here.\n",
    "\n",
    "In the cell below:\n",
    "- Define the moving average impulse responses as `MA5, MA25, MA75` respectively.\n",
    "    - Again, don't bother with any zero padding - just define them at their nonzero points.\n",
    "- Filter your test data (`data`) with each of them using **convolution with the \"same\" mode**. We'll call the outputs `y5, y25`, and `y75`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* **Here, we are *not* using causal moving averages as we did in Q2a.** The motivation in doing so is that we want the filtered signals to temporally align with the original to make the results easier to interpret. While real-time filters have to be causal, we're working in an offline setting with pre-collected data here, so causality is less important, and interpretability is more useful. These properties are some of the tradeoffs involved in how data processing is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting code has been provided for you. To generate the results, simply run the cell after adding your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = stock_prices[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO your impulse response definitions here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO your filtering code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay stock prices\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(np.arange(len(data)), data)\n",
    "plt.plot(np.arange(len(data)), y5)\n",
    "plt.plot(np.arange(len(data)), y25)\n",
    "plt.plot(np.arange(len(data)), y75)\n",
    "\n",
    "# Formatting mumbo jumbo to abstract away boundary issues\n",
    "plt.xlim([40, 360])\n",
    "plt.ylim([140, 240])\n",
    "plt.legend(('Original Data', '5-Point Average', '25-Point Average', '75-Point Average'), bbox_to_anchor=(1.1, 1.05))\n",
    "plt.ylabel(\"US Dollars\")\n",
    "plt.xlabel(\"Days Since June 23, 2017\")\n",
    "plt.title(\"Moving Averaged AAPL Stock Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** As we use longer and longer moving average filters to process our signal (the stock data), does the filtered signal highlight longer term trends, or shorter term trends? Explain in 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Suppose that you had the closing price of Microsoft stock (MSFT) for every day it's existed, 1986 to present (~8000-10000 data points, one per day), and wanted to see how the company's stock price changed at the level of trends that occur over the course of a year using a moving average filter. How long of a moving average would you use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: The MACD Indicator\n",
    "\n",
    "The Moving Average Convergence Divergence (MACD) Indicator is a trend-following momentum indicator that shows the relationship between two moving averages of a stockâ€™s price. In this question, we'll use the MACD indicator as a vehicle for introducing the exponential moving average as well as some more uses of signal processing in financial analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Exponential Moving Average\n",
    "\n",
    "To calculate the MACD of a stock, we first have to understand a new kind of moving average, called the *Exponential Moving Average* (EMA). What we did earlier is known as an Simple Moving Average (SMA) - all points are given equal weight. An EMA, on the other hand, places a greater weight, and therefore significance, on the most recent data points. The benefit of the EMA over the SMA is that the EMA reacts faster to recent price changes. \n",
    "\n",
    "### Derivation\n",
    "\n",
    "Let's take a look at where the EMA comes from. We can express the EMA using the following recursive LCCDE: \n",
    "\n",
    "$$y[n]=\\alpha\\cdot x[n] + (1-\\alpha)\\cdot y[n-1]$$\n",
    "\n",
    "where $y[n]$ is the EMA at day $n$, and $x[n]$ is the stock price at day $n$. Now, why is this an \"exponential\" moving average? It might not be obvious when written it in this form. Let's write it out step by step to try to unravel the recursion. Assuming that $y[n]$ is zero $\\forall n<0$,\n",
    "\n",
    "$\\begin{aligned}\n",
    "    y[0] &= \\alpha\\cdot x[0] + (1-\\alpha)\\cdot y[-1] = \\alpha\\cdot x[0] \\\\\n",
    "    y[1] &= \\alpha\\cdot x[1] + (1-\\alpha)\\cdot y[0] = \\alpha\\cdot x[1] + (1-\\alpha)\\cdot \\alpha\\cdot x[0] \\\\\n",
    "    y[2] &= \\alpha\\cdot x[2] + (1-\\alpha)\\cdot y[1] = \\alpha\\cdot x[2] + (1-\\alpha)\\cdot (\\alpha\\cdot x[1] + (1-\\alpha)\\cdot \\alpha\\cdot x[0]) = \\alpha\\cdot x[2] + (1-\\alpha)\\cdot \\alpha\\cdot x[1] + (1-\\alpha)^2\\cdot \\alpha\\cdot x[0] \\\\\n",
    "    &\\vdots \\\\\n",
    "    y[n] &= \\alpha\\sum_{k=0}^{n}(1-\\alpha)^k\\cdot x[n-k]\n",
    "\\end{aligned}$\n",
    "\n",
    "Aha! Now that we have rewritten it, it's clear why we call this an EMA - we are weighting each previous data point with an value that decreases exponentially as we go further and further back in time.\n",
    "\n",
    "### An LTI Perspective: The Impulse Response of an EMA Filter\n",
    "\n",
    "We can apply a Kronecker delta to the EMA system by setting $x[n] = \\delta[n]$ to find its impulse response:\n",
    "\n",
    "$$h[n]=\\alpha\\sum_{k=0}^{n}(1-\\alpha)^k\\cdot \\delta[n-k]= \\alpha (1-\\alpha)^n u[n]$$\n",
    "\n",
    "which is just what we would expect: a (one-sided) decaying exponential!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Job\n",
    "\n",
    "Fill in the `ema_filter` function below to create and return the impulse response of an EMA filter truncated after `length` points. The value of $\\alpha$ has been determined for you already. **Make sure you normalize the impulse response to sum to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ema_filter(length):\n",
    "    alpha = 2/(length+1)\n",
    "    # TODO: Create and return an EMA filter with length \"length\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me to plot!\n",
    "h = ema_filter(5)\n",
    "plt.figure()\n",
    "plt.title(\"Length 5 EMA impulse response\")\n",
    "plt.xlim([-.5, 4.5])\n",
    "plt.stem(h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convolve data with the impulse response to calculate the EMA! Note that if we flipped this signal (as we'd do in convolving) and slid it across some data signal, pointwise multiplying and summing to calculate our EMA, the strongest point would always be at the front, with an exponential drop-off as we go further and further back along the impulse response.\n",
    "\n",
    "**2 Quick Things to Note:**\n",
    "\n",
    "1. The LCCDE we originally gave describes an IIR filter, but we are using an FIR filter - after all, we can't store infinitely many values on a computer. In order to account for this, we truncate as is typically done, but we also renormalize so that the sum of the impulse response's coefficients, known as the DC gain, is 1.\n",
    "\n",
    "2. The value for $\\alpha$ that we have picked is motivated by reducing the output noise variance. We have a provided a reference below if you wish to read more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MACD Line\n",
    "\n",
    "The *MACD line* is calculated by taking the difference between the 26-day EMA of the stock and its 12-day EMA. In the cell below, we've defined an array of values, `data`, for you based on the same AAPL stock data we used earlier in this lab. In the cell below, calculate the MACD line. To do so,\n",
    "- Create a length 26 EMA filter, $h_{26}$.\n",
    "- Create a length 12 EMA filter, $h_{12}$.\n",
    "- Calculate the 26-day EMA as $y_{26} = x * h_{26}$, where $x$ is `data`. **Use \"valid\" as the convolution mode** - we only want points where our signals fully overlap.\n",
    "- Calculate the 12-day EMA as $y_{12} = x * h_{12}$. Again, use \"valid\" as the convolution mode.\n",
    "- Crop $y_{12}$ by discarding its first 14 values, so that $y_{26}$ and $y_{12}$ have the same length. \n",
    "    - The first value in $y_{26}$ is an EMA taken over data points 1 through 26 (since the first point the signals fully overlap is at day 26), representing the exponential average at day 26, factoring in the previous 25 days. By cropping out the first 14 values of $y_{12}$, we ensure the first point in its output also corresponds to an EMA for day 26, but taken over the most recent 12 days rather than 26, essentially \"aligning\" the outputs.\n",
    "- Compute the MACD line as $y_{12} - y_{26}$. **Store your result in a variable called `MACD`, as our plotting code uses this.**\n",
    "\n",
    "After you finish, run the next cell to plot the results; here's the plot from the staff solution so you're able to check that your answer is correct before moving on:\n",
    "\n",
    "<img src=\"macd.png\" width=\"1100px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock data\n",
    "data = stock_prices[start:end]\n",
    "\n",
    "# TODO calculate macd line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Code\n",
    "x = np.arange(len(MACD))\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "plt.xticks(x[::15], stock_dates[start+26:end:15], fontsize=10, rotation=75)\n",
    "plt.plot(MACD)\n",
    "plt.title(\"MACD Line for AAPL Stock (8/1/2017 - 1/7/2019)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Signal Line\n",
    "\n",
    "Now that we have the MACD line, we want to take the 9-day EMA of the MACD line to create the *signal line*. Once equipped with the MACD line and the signal line, we can analyze the stock data. \n",
    "\n",
    "Add code in the top of the cell below to calculate the signal line by applying a 9-day EMA filter (use \"same\" as the convolution mode this time) to your MACD line, `MACD`, from above. Plotting code has been provided for you. **Store the result in a variable called `signal`, as this is what our plotting code uses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO your signal line calculation here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Code\n",
    "c = ['green', 'red']\n",
    "colors = [c[bool(i)] for i in np.greater(signal, MACD)]\n",
    "x = np.arange(len(signal))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title(\"Stock Price\")\n",
    "plt.plot(data)\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"MACD, Signal, and Histogram\")\n",
    "plt.xticks(x[::15], stock_dates[start+26:end:15], fontsize=10, rotation=75)\n",
    "plt.plot(MACD, label='MACD Line')\n",
    "plt.plot(signal, label='Signal Line')\n",
    "plt.bar(range(len(signal)),(MACD-signal), color=colors, label=\"Difference Histogram\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, you should see that the signal line resembles a smoothed, shifted (slightly to the left) version of the MACD line, and the difference histogram is green where the MACD Line is above the signal line, and red where the signal line is above the MACD line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the MACD Indicator (from *Technical Analysis* [3])\n",
    "\n",
    "In signal processing terms, the MACD is a filtered measure of velocity. The velocity has been passed through two first-order linear low-pass filters (the EMA filters). The signal line is that resulting velocity, filtered again. The difference between those two, the histogram, is a measure of the acceleration, with all three filters applied. A MACD crossover of the signal line indicates that the direction of the acceleration is changing. The MACD line crossing zero suggests that the average velocity is changing direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Using this analogy of velocity and acceleration, we can think of a stock's price as a the position of the car. We know its velocity and acceleration from the MACD and histogram, respectively. What do points where the difference histogram is positive tell us about how the stock is behaving, and how can we use this inforamtion to decide whether or not to invest in a stock? How about when the difference histogram is negative?\n",
    "\n",
    "<span style=\"color:blue\">**A:** (TODO)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Excerpt from an online signal processing textbook on the use of Moving Average Filters for noise reduction. [Link](https://www.analog.com/media/en/technical-documentation/dsp-book/dsp_book_Ch15.pdf)  \n",
    "[2] Overview of the MACD indicator. [Link](https://www.investopedia.com/terms/m/macd.asp)  \n",
    "[3] *Technical Analysis*. [Link](http://www.mrao.cam.ac.uk/~mph/Technical_Analysis.pdf)  \n",
    "[4] Exponential Moving Average Resource. [Link](https://tttapa.github.io/Pages/Mathematics/Systems-and-Control-Theory/Digital-filters/Exponential%20Moving%20Average/Exponential-Moving-Average.html) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
